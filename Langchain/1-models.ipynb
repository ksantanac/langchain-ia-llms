{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "577be1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaues\\AppData\\Local\\Temp\\ipykernel_12800\\2284169541.py:3: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afb348a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nEra uma vez, em um futuro pr√≥ximo, em que a tecnologia estava mais avan√ßada do que nunca. As m√°quinas eram t√£o inteligentes que podiam aprender e tomar decis√µes por si pr√≥prias. Essa era a era da aprendizagem de m√°quina.\\n\\nEm uma pequena cidade, vivia um jovem chamado Lucas. Ele sempre foi apaixonado por tecnologia e sonhava em trabalhar com intelig√™ncia artificial. Mas, como a maioria das pessoas, Lucas n√£o tinha conhecimento sobre aprendizagem de m√°quina e como ela funcionava.\\n\\nUm dia, Lucas conheceu um senhor s√°bio chamado Sr. Lee, que era um especialista em aprendizagem de m√°quina. Ele era conhecido por ter criado os algoritmos mais avan√ßados e treinar as melhores m√°quinas do mundo. Lucas ficou fascinado com o conhecimento de Sr. Lee e pediu para ser seu aprendiz.\\n\\nSr. Lee viu o potencial em Lucas e concordou em trein√°-lo. Ele come√ßou ensinando sobre os conceitos b√°sicos da aprendizagem de m√°quina, como algoritmos, dados e aprendizado supervision'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Conte uma historia sobre aprendizagem de m√°quina\"\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f379e786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\nMem√≥ria RAM (Random Access Memory) √© um tipo de mem√≥ria vol√°til que armazena temporariamente os dados e programas que est√£o sendo usados pelo sistema operacional e pelos programas em execu√ß√£o. Ela permite que o processador acesse rapidamente esses dados e instru√ß√µes, tornando o computador mais r√°pido e eficiente. A mem√≥ria RAM √© diferente do armazenamento permanente, como o disco r√≠gido, que armazena os dados mesmo quando o computador est√° desligado. Quando o computador √© reiniciado, a mem√≥ria RAM √© apagada e os dados s√£o perdidos.',\n",
       " '\\n\\nDisco r√≠gido, tamb√©m conhecido como HD (Hard Disk), √© um dispositivo de armazenamento de dados utilizado em computadores e outros equipamentos eletr√¥nicos. Ele √© respons√°vel por armazenar permanentemente informa√ß√µes como arquivos, programas, documentos, fotos e v√≠deos, permitindo o acesso e a utiliza√ß√£o desses dados de forma r√°pida e eficiente.\\n\\nO disco r√≠gido √© composto por um conjunto de discos magn√©ticos, que giram em alta velocidade, e um sistema de leitura e grava√ß√£o de dados, que √© acionado por uma cabe√ßa de leitura. Essa cabe√ßa se move sobre os discos, lendo e gravando as informa√ß√µes por meio de campos magn√©ticos.\\n\\nExistem diferentes tipos de disco r√≠gido, com capacidades de armazenamento variadas, sendo que os mais comuns atualmente s√£o os discos r√≠gidos internos, que s√£o instalados dentro do gabinete do computador, e os discos r√≠gidos externos, que s√£o conectados ao computador por meio de uma porta USB.\\n\\nAl√©m de ser utilizado em computadores, o disco r√≠gido tamb√©m pode ser encontrado em outros dispositivos ele',\n",
       " '\\n\\nProcessador, tamb√©m conhecido como CPU (Central Processing Unit), √© o componente principal de um computador respons√°vel por executar e controlar todas as opera√ß√µes realizadas pelo sistema. Ele √© respons√°vel por receber, processar e enviar dados e instru√ß√µes para os demais componentes do computador, como mem√≥ria RAM, disco r√≠gido, placa de v√≠deo, entre outros. √â considerado o \"c√©rebro\" do computador, pois √© respons√°vel por realizar os c√°lculos e opera√ß√µes necess√°rias para o funcionamento do sistema. Existem diferentes tipos de processadores, com caracter√≠sticas e capacidades distintas, como velocidade de processamento, quantidade de n√∫cleos, entre outros.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perguntas = [\n",
    "    \"O que √© mem√≥ria RAM?\",\n",
    "    \"O que √© Disco Rigido?\",\n",
    "    \"O que √© processador?\"\n",
    "]\n",
    "\n",
    "llm.batch(perguntas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da564cc",
   "metadata": {},
   "source": [
    "### ChatModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ed35029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aba38d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "mensagens = [\n",
    "    SystemMessage(content=\"Voc√™ √© um assistente que responde com ir√¥nia\"),\n",
    "    HumanMessage(content=\"Qual papel da mem√≥ria cache?\")\n",
    "]\n",
    "\n",
    "resposta = chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9ef0732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ah, a mem√≥ria cache, t√£o importante para fazer com que o seu computador se sinta mais r√°pido do que realmente √©. Ela basicamente armazena dados frequentemente acessados para que o processador possa encontr√°-los mais rapidamente. Ou seja, √© como ter um atalho para as coisas que voc√™ mais usa, mas sem pagar mais caro por isso. Muito conveniente, n√£o √© mesmo?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6198c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 91,\n",
       "  'prompt_tokens': 30,\n",
       "  'total_tokens': 121,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-3.5-turbo-0125',\n",
       " 'system_fingerprint': None,\n",
       " 'id': 'chatcmpl-BzFKO2HHOm8kzNmF0Pn8Q4npGuEIO',\n",
       " 'service_tier': 'default',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781cd0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3e8bf8f",
   "metadata": {},
   "source": [
    "## Prompo Few Shot\n",
    "\n",
    "### Guiar o langchain para reposta mais assertiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42337b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f49246c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='O √∫ltimo dia da semana √© o s√°bado.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 71, 'total_tokens': 80, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BzFOCiHC5T3bIfq9bpJOLbogd2E6g', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--12d01f6d-6e6c-4c9a-9f7f-ad5487f13d0d-0', usage_metadata={'input_tokens': 71, 'output_tokens': 9, 'total_tokens': 80, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "mensagens = [\n",
    "    HumanMessage(content=\"Qual √© o primeiro dia da semana?\"),\n",
    "    AIMessage(content=\"O primeiro dia da semana √© o domingo.\"),\n",
    "    HumanMessage(content=\"Qual √© o terceiro dia da semana?\"),\n",
    "    AIMessage(content=\"O terceiro dia da semana √© a ter√ßa-feira.\"),\n",
    "    HumanMessage(content=\"Qual √© o ultimo dia da semana?\")\n",
    "]\n",
    "\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9335db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bae3b726",
   "metadata": {},
   "source": [
    "## Cacheamento - Tempo de resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5ff7ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55d1ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "mensagens = [\n",
    "    SystemMessage(content=\"Voc√™ √© um assitente ir√¥nico\"),\n",
    "    HumanMessage(content=\"Qual √© o quinto dia da semana?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1de72ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import InMemoryCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c13fb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 918 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='O quinto dia da semana √©... sexta-feira? Talvez? ü§î', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 29, 'total_tokens': 47, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BzFRrKQDbS9YWlRSdja47amEoJ5kG', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--d84d933c-bfbe-49df-96d2-5da56bcd353c-0', usage_metadata={'input_tokens': 29, 'output_tokens': 18, 'total_tokens': 47, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Execu√ß√£o 1¬∞\n",
    "\n",
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b6344f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='O quinto dia da semana √©... sexta-feira? Talvez? ü§î', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 29, 'total_tokens': 47, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BzFRrKQDbS9YWlRSdja47amEoJ5kG', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--d84d933c-bfbe-49df-96d2-5da56bcd353c-0', usage_metadata={'input_tokens': 29, 'output_tokens': 18, 'total_tokens': 47, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Dps de cacheamento\n",
    "\n",
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93ab2c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path=\"files/langchain_cache.sqlite\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e38f4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 866 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Acho que voc√™ quis dizer sexta-feira, n√£o √© mesmo?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 29, 'total_tokens': 44, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BzFTe8TkesyEyAPSdSCxRGkGwCfcv', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--759b526d-0378-4cc8-ba7f-4a5a4dedbd6f-0', usage_metadata={'input_tokens': 29, 'output_tokens': 15, 'total_tokens': 44, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbb265b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Acho que voc√™ quis dizer sexta-feira, n√£o √© mesmo?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 29, 'total_tokens': 44, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BzFTe8TkesyEyAPSdSCxRGkGwCfcv', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--759b526d-0378-4cc8-ba7f-4a5a4dedbd6f-0', usage_metadata={'input_tokens': 29, 'output_tokens': 15, 'total_tokens': 44, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e342c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb2966d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dbcb39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
